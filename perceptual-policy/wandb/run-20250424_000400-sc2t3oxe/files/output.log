Using device: cuda
buffer limit is =  500000
Episode: 0, total numsteps: 0, return: -1.0
Episode: 0, total numsteps: 0, return: -1.0
Episode: 0, total numsteps: 0, return: -1.0
Episode: 0, total numsteps: 0, return: -1.0
Episode: 0, total numsteps: 0, return: -1.0
Episode: 1, total numsteps: 20, return: -1.0
Cumulative Returns: -1.0
Episode: 2, total numsteps: 40, return: -1.0
Cumulative Returns: -2.0
Episode: 3, total numsteps: 60, return: -1.0
Cumulative Returns: -3.0
Episode: 4, total numsteps: 80, return: -1.0
Cumulative Returns: -4.0
Episode: 5, total numsteps: 100, return: -1.0
Cumulative Returns: -5.0
Episode: 6, total numsteps: 120, return: -1.0
Cumulative Returns: -6.0
Episode: 7, total numsteps: 140, return: -1.0
Cumulative Returns: -7.0
Episode: 8, total numsteps: 160, return: -1.0
Cumulative Returns: -8.0
Episode: 9, total numsteps: 180, return: -1.0
Cumulative Returns: -9.0
Episode: 10, total numsteps: 200, return: -1.0
Cumulative Returns: -10.0
Episode: 11, total numsteps: 220, return: -1.0
Cumulative Returns: -11.0
Episode: 12, total numsteps: 240, return: -1.0
Cumulative Returns: -12.0
Episode: 13, total numsteps: 260, return: -1.0
Cumulative Returns: -13.0
Episode: 14, total numsteps: 280, return: -1.0
Cumulative Returns: -14.0
Episode: 15, total numsteps: 300, return: -1.0
Cumulative Returns: -15.0
Episode: 16, total numsteps: 320, return: -1.0
Cumulative Returns: -16.0
Episode: 17, total numsteps: 340, return: -1.0
Cumulative Returns: -17.0
Episode: 18, total numsteps: 360, return: -1.0
Cumulative Returns: -18.0
Episode: 19, total numsteps: 380, return: -1.0
Cumulative Returns: -19.0
Episode: 20, total numsteps: 400, return: -1.0
Cumulative Returns: -20.0
Episode: 21, total numsteps: 420, return: -1.0
Cumulative Returns: -21.0
Episode: 22, total numsteps: 440, return: -1.0
Cumulative Returns: -22.0
Episode: 23, total numsteps: 460, return: -1.0
Cumulative Returns: -23.0
Episode: 24, total numsteps: 480, return: -1.0
Cumulative Returns: -24.0
Episode: 25, total numsteps: 500, return: -1.0
Cumulative Returns: -25.0
Episode: 26, total numsteps: 520, return: -1.0
Cumulative Returns: -26.0
Episode: 27, total numsteps: 540, return: -1.0
Cumulative Returns: -27.0
Episode: 28, total numsteps: 560, return: -1.0
Cumulative Returns: -28.0
Episode: 29, total numsteps: 580, return: -1.0
Cumulative Returns: -29.0
Episode: 30, total numsteps: 600, return: -1.0
Cumulative Returns: -30.0
Episode: 31, total numsteps: 620, return: -1.0
Cumulative Returns: -31.0
Episode: 32, total numsteps: 640, return: -1.0
Cumulative Returns: -32.0
Episode: 33, total numsteps: 660, return: -1.0
Cumulative Returns: -33.0
Episode: 34, total numsteps: 680, return: -1.0
Cumulative Returns: -34.0
Episode: 35, total numsteps: 700, return: -1.0
Cumulative Returns: -35.0
Episode: 36, total numsteps: 720, return: -1.0
Cumulative Returns: -36.0
Episode: 37, total numsteps: 740, return: -1.0
Cumulative Returns: -37.0
Episode: 38, total numsteps: 760, return: -1.0
Cumulative Returns: -38.0
Episode: 39, total numsteps: 780, return: -1.0
Cumulative Returns: -39.0
Episode: 40, total numsteps: 800, return: -1.0
Cumulative Returns: -40.0
Episode: 41, total numsteps: 820, return: -1.0
Cumulative Returns: -41.0
Episode: 42, total numsteps: 840, return: -1.0
Cumulative Returns: -42.0
Episode: 43, total numsteps: 860, return: -1.0
Cumulative Returns: -43.0
Episode: 44, total numsteps: 880, return: -1.0
Cumulative Returns: -44.0
Episode: 45, total numsteps: 900, return: -1.0
Cumulative Returns: -45.0
Episode: 46, total numsteps: 920, return: -1.0
Cumulative Returns: -46.0
Episode: 47, total numsteps: 940, return: -1.0
Cumulative Returns: -47.0
Episode: 48, total numsteps: 960, return: -1.0
Cumulative Returns: -48.0
Episode: 49, total numsteps: 980, return: -1.0
Cumulative Returns: -49.0
Episode: 50, total numsteps: 1000, return: -1.0
Cumulative Returns: -50.0
Episode: 51, total numsteps: 1020, return: -1.0
Cumulative Returns: -51.0
Episode: 52, total numsteps: 1040, return: -1.0
Cumulative Returns: -52.0
Episode: 53, total numsteps: 1060, return: -1.0
Cumulative Returns: -53.0
Episode: 54, total numsteps: 1080, return: -1.0
Cumulative Returns: -54.0
Episode: 55, total numsteps: 1100, return: -1.0
Cumulative Returns: -55.0
Episode: 56, total numsteps: 1120, return: -1.0
Cumulative Returns: -56.0
Episode: 57, total numsteps: 1140, return: -1.0
Cumulative Returns: -57.0
Episode: 58, total numsteps: 1160, return: -1.0
Cumulative Returns: -58.0
Episode: 59, total numsteps: 1180, return: -1.0
Cumulative Returns: -59.0
Episode: 60, total numsteps: 1200, return: -1.0
Cumulative Returns: -60.0
Episode: 61, total numsteps: 1220, return: -1.0
Cumulative Returns: -61.0
Episode: 62, total numsteps: 1240, return: -1.0
Cumulative Returns: -62.0
Episode: 63, total numsteps: 1260, return: -1.0
Cumulative Returns: -63.0
Episode: 64, total numsteps: 1280, return: -1.0
Cumulative Returns: -64.0
Episode: 65, total numsteps: 1300, return: -1.0
Cumulative Returns: -65.0
Episode: 66, total numsteps: 1320, return: -1.0
Cumulative Returns: -66.0
Episode: 67, total numsteps: 1340, return: -1.0
Cumulative Returns: -67.0
Episode: 68, total numsteps: 1360, return: -1.0
Cumulative Returns: -68.0
Episode: 69, total numsteps: 1380, return: -1.0
Cumulative Returns: -69.0
Episode: 70, total numsteps: 1400, return: -1.0
Cumulative Returns: -70.0
Episode: 71, total numsteps: 1420, return: -1.0
Cumulative Returns: -71.0
Episode: 72, total numsteps: 1440, return: -1.0
Cumulative Returns: -72.0
Episode: 73, total numsteps: 1460, return: -1.0
Cumulative Returns: -73.0
Episode: 74, total numsteps: 1480, return: -1.0
Cumulative Returns: -74.0
Episode: 75, total numsteps: 1500, return: -1.0
Cumulative Returns: -75.0
Episode: 76, total numsteps: 1520, return: -1.0
Cumulative Returns: -76.0
Episode: 77, total numsteps: 1540, return: -1.0
Cumulative Returns: -77.0
Episode: 78, total numsteps: 1560, return: -1.0
Cumulative Returns: -78.0
Episode: 79, total numsteps: 1580, return: -1.0
Cumulative Returns: -79.0
Episode: 80, total numsteps: 1600, return: -1.0
Cumulative Returns: -80.0
Episode: 81, total numsteps: 1620, return: -1.0
Cumulative Returns: -81.0
Episode: 82, total numsteps: 1640, return: -1.0
Cumulative Returns: -82.0
Episode: 83, total numsteps: 1660, return: -1.0
Cumulative Returns: -83.0
Episode: 84, total numsteps: 1680, return: -1.0
Cumulative Returns: -84.0
Episode: 85, total numsteps: 1700, return: -1.0
Cumulative Returns: -85.0
Episode: 86, total numsteps: 1720, return: -1.0
Cumulative Returns: -86.0
Episode: 87, total numsteps: 1740, return: -1.0
Cumulative Returns: -87.0
Episode: 88, total numsteps: 1760, return: -1.0
Cumulative Returns: -88.0
Episode: 89, total numsteps: 1780, return: -1.0
Cumulative Returns: -89.0
Episode: 90, total numsteps: 1800, return: -1.0
Cumulative Returns: -90.0
Episode: 91, total numsteps: 1820, return: -1.0
Cumulative Returns: -91.0
Episode: 92, total numsteps: 1840, return: -1.0
Cumulative Returns: -92.0
Episode: 93, total numsteps: 1860, return: -1.0
Cumulative Returns: -93.0
Episode: 94, total numsteps: 1880, return: -1.0
Cumulative Returns: -94.0
Episode: 95, total numsteps: 1900, return: -1.0
Cumulative Returns: -95.0
Episode: 96, total numsteps: 1920, return: -1.0
Cumulative Returns: -96.0
Episode: 97, total numsteps: 1940, return: -1.0
Cumulative Returns: -97.0
Episode: 98, total numsteps: 1960, return: -1.0
Cumulative Returns: -98.0
Episode: 99, total numsteps: 1980, return: -1.0
Cumulative Returns: -99.0
Episode: 100, total numsteps: 2000, return: -1.0
Cumulative Returns: -100.0
Episode: 101, total numsteps: 2020, return: -1.0
Cumulative Returns: -101.0
Episode: 102, total numsteps: 2040, return: -1.0
Cumulative Returns: -102.0
Episode: 103, total numsteps: 2060, return: -1.0
Cumulative Returns: -103.0
Episode: 104, total numsteps: 2080, return: -1.0
Cumulative Returns: -104.0
Episode: 105, total numsteps: 2100, return: -1.0
Cumulative Returns: -105.0
Episode: 106, total numsteps: 2120, return: -1.0
Cumulative Returns: -106.0
Episode: 107, total numsteps: 2140, return: -1.0
Cumulative Returns: -107.0
Episode: 108, total numsteps: 2160, return: -1.0
Cumulative Returns: -108.0
Episode: 109, total numsteps: 2180, return: -1.0
Cumulative Returns: -109.0
Episode: 110, total numsteps: 2200, return: -1.0
Cumulative Returns: -110.0
Episode: 111, total numsteps: 2220, return: -1.0
Cumulative Returns: -111.0
Episode: 112, total numsteps: 2240, return: -1.0
Cumulative Returns: -112.0
Episode: 113, total numsteps: 2260, return: -1.0
Cumulative Returns: -113.0
Episode: 114, total numsteps: 2280, return: -1.0
Cumulative Returns: -114.0
Episode: 115, total numsteps: 2300, return: -1.0
Cumulative Returns: -115.0
Episode: 116, total numsteps: 2320, return: -1.0
Cumulative Returns: -116.0
Episode: 117, total numsteps: 2340, return: -1.0
Cumulative Returns: -117.0
Episode: 118, total numsteps: 2360, return: -1.0
Cumulative Returns: -118.0
Episode: 119, total numsteps: 2380, return: -1.0
Cumulative Returns: -119.0
Episode: 120, total numsteps: 2400, return: -1.0
Cumulative Returns: -120.0
Episode: 121, total numsteps: 2420, return: -1.0
Cumulative Returns: -121.0
Episode: 122, total numsteps: 2440, return: -1.0
Cumulative Returns: -122.0
Episode: 123, total numsteps: 2460, return: -1.0
Cumulative Returns: -123.0
Episode: 124, total numsteps: 2480, return: -1.0
Cumulative Returns: -124.0
Episode: 125, total numsteps: 2500, return: -1.0
Cumulative Returns: -125.0
Traceback (most recent call last):
  File "/home/themandalorian/ETH/Thesis/perceptualpolicy/main-alm.py", line 274, in <module>
    alm_helper.train()
  File "/home/themandalorian/ETH/Thesis/perceptualpolicy/main-alm.py", line 141, in train
    self.agent.update(self._train_step)
  File "/home/themandalorian/ETH/Thesis/perceptualpolicy/alm.py", line 119, in update
    self.update_rest(std, step, log, metrics)
  File "/home/themandalorian/ETH/Thesis/perceptualpolicy/alm.py", line 223, in update_rest
    self.update_actor(z_dist.sample(), std, log, metrics)
  File "/home/themandalorian/ETH/Thesis/perceptualpolicy/alm.py", line 298, in update_actor
    actor_loss.backward()
  File "/home/themandalorian/anaconda3/envs/alm/lib/python3.10/site-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
KeyboardInterrupt